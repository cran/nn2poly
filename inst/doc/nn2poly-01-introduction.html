<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Pablo Morala" />


<title>Introduction to nn2poly</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to nn2poly</h1>
<h4 class="author">Pablo Morala</h4>


<div id="TOC">
<ul>
<li><a href="#nn2poly-package-goal" id="toc-nn2poly-package-goal"><code>nn2poly</code> package goal</a></li>
<li><a href="#this-vignette-a-first-example" id="toc-this-vignette-a-first-example">This vignette: a first
example</a>
<ul>
<li><a href="#polynomial-structure-in-nn2poly" id="toc-polynomial-structure-in-nn2poly">Polynomial structure in
<code>nn2poly</code></a></li>
<li><a href="#simulated-data" id="toc-simulated-data">Simulated
data</a></li>
<li><a href="#original-neural-network" id="toc-original-neural-network">Original neural network</a></li>
<li><a href="#building-the-needed-input-for-default-nn2poly" id="toc-building-the-needed-input-for-default-nn2poly">Building the
needed input for default <code>nn2poly</code></a></li>
<li><a href="#polynomial-obtained-with-nn2poly-from-weights-and-activation-functions" id="toc-polynomial-obtained-with-nn2poly-from-weights-and-activation-functions">Polynomial
obtained with <code>nn2poly</code> from weights and activation
functions</a></li>
<li><a href="#predictions-using-the-obtained-polynomial" id="toc-predictions-using-the-obtained-polynomial">Predictions using the
obtained polynomial</a></li>
<li><a href="#visualizing-the-results" id="toc-visualizing-the-results">Visualizing the results</a></li>
</ul></li>
</ul>
</div>

<div id="nn2poly-package-goal" class="section level1">
<h1><code>nn2poly</code> package goal</h1>
<p>The main objective of <code>nn2poly</code> is to obtain a
representation of a feed forward artificial neural network (like a
multilayered perceptron) in terms of a polynomial representation. The
coefficients of such polynomials are obtained by applying first a Taylor
expansion at each activation function in the neural network. Then, this
expansions and the given neural network weights are joint using
combinatorial properties, obtaining a final value for the polynomial
coefficients. The main goal of this new representation is to obtain an
interpretable model, serving thus as an eXplainable Artificial
Intelligence (XAI) tool to overcome the black box nature of neural
networks by means of interpreting the effect of those obtained
polynomial coefficients.</p>
<p>More information with the theoretical insights about the underlying
mathematical process used to build this relationship can be found in the
following references:</p>
<ul>
<li><p>Pablo Morala, J. Alexandra Cifuentes, Rosa E. Lillo, Iñaki Ucar
(2021). “Towards a mathematical framework to inform neural network
modelling via polynomial regression.” <em>Neural Networks</em>,
<em>142</em>, 57-72. doi: <a href="https://doi.org/10.1016/j.neunet.2021.04.036">10.1016/j.neunet.2021.04.036</a></p></li>
<li><p>Pablo Morala, J. Alexandra Cifuentes, Rosa E. Lillo, Iñaki Ucar
(2023). “NNN2Poly: A Polynomial Representation for Deep Feed-Forward
Artificial Neural Networks.” <em>IEEE Transactions on Neural Networks
and Learning Systems</em>, (Early Access). doi: <a href="https://doi.org/10.1109/TNNLS.2023.3330328">10.1109/TNNLS.2023.3330328</a></p></li>
</ul>
<blockquote>
<p><em>Important remark</em>: The approximations made by NN2Poly rely on
Taylor expansions and therefore require some constraints to be imposed
when training the original neural network in order to have those
expansions controlled. The implementation of these constraints depends
on the deep learning framework used to train the neural networks.
Frameworks currently supported are <em>tensorflow</em> and
<em>torch</em>. Details on how constraints are applied on each framework
are covered in
<code>vignette(&quot;nn2poly-02-supported-DL-frameworks&quot;)</code>. However,
<code>nn2poly</code> can work by default with any kind of neural network
by manually feeding the neural network weights and activation functions
to the algorithm. Therefore, <code>nn2poly</code> is not limited to any
of the supported deep learning frameworks.</p>
</blockquote>
</div>
<div id="this-vignette-a-first-example" class="section level1">
<h1>This vignette: a first example</h1>
<p>In this vignette we present the basic behavior of
<code>nn2poly</code> when used in its default version, without
specifying any deep learning framework as explained in the previous
remark. For that matter, we will showcase an example where we will get
the weights from a trained neural network and manually create the object
with the needed information to use <code>nn2poly</code>.</p>
<p>The result will be a polynomial that tries to approximate the neural
network behavior. In this case the neural network training will not have
any constraints imposed. Then, as explained previously, the final
approximation by the polynomial may not be accurate enough.</p>
<p>This example is focused in the default version, but, as we need to
build a NN under some framework, we will use <code>keras</code> and
<code>tensorflow</code> for that matter. In any case, the needed
parameters will be extracted and used under the default version of
<code>nn2poly</code>, so this can be extrapolated to any other
framework.</p>
<p>In particular, we will solve a really simple regression problem using
simulated data from a polynomial, which allows us to have a ground truth
and control if the final polynomial coefficients obtained with
<code>nn2poly</code> are similar to those from the polynomial that
originates the data.</p>
<blockquote>
<p><em>Note</em>: For a classification example please refer to
<code>vignette(&quot;nn2poly-03-classification-example&quot;)</code></p>
</blockquote>
<div id="polynomial-structure-in-nn2poly" class="section level2">
<h2>Polynomial structure in <code>nn2poly</code></h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(nn2poly)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span></code></pre></div>
<p>As the final output of using <code>nn2poly</code> on a neural network
is a polynomial (or several ones in classification problems), the
package uses a certain structure to represent those polynomials and it
also provides <code>nn2poly:::eval_poly()</code>, a function to evaluate
polynomials in that structure. As we will use it to generate the
simulated data in this example, we first define a polynomial using the
format needed in <code>nn2poly</code>, which consists of a list
containing: * Labels: A list of integer vectors denoting the
combinations of variables that appear on each term of the polynomial.
Variables are numbered from <code>1</code> to <code>p</code> where
<code>p</code> is the dimension of the problem. As an example,
<code>c(1,1,3)</code> would represent the term <span class="math inline">\(x_1^2x_3\)</span>. An special case is the
intercept term, which is represented by <code>0</code> * Values: Vector
containing the numerical values of the coefficients denoted by labels.
If multiple polynomials with the same labels but different coefficient
values are wanted, a matrix can be employed, where each row represents a
polynomial.</p>
<p>Here we create the polynomial <span class="math inline">\(4x_1 - 3
x_2x_3\)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>polynomial <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>polynomial<span class="sc">$</span>labels <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="dv">1</span>), <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>polynomial<span class="sc">$</span>values <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="sc">-</span><span class="dv">3</span>)</span></code></pre></div>
</div>
<div id="simulated-data" class="section level2">
<h2>Simulated data</h2>
<p>With said polynomial, we can now generate the desired data that will
train the NN for our example. We will employ a normal distribution to
generate variables <span class="math inline">\(x_1, x_2, x_3\)</span>
and also an error term <span class="math inline">\(\epsilon\)</span>.
Therefore, the response variable <span class="math inline">\(y\)</span>
will be generated as: <span class="math inline">\(y = 4x_1 - 3 x_2x_3 +
\epsilon\)</span></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Define number of variables and sample size</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>n_sample <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co"># Predictor variables</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,n_sample,p)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>p){</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>  X[,i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n_sample,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>}</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co"># Response variable + small error term</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>Y <span class="ot">&lt;-</span> nn2poly<span class="sc">:::</span><span class="fu">eval_poly</span>(<span class="at">poly =</span> polynomial, <span class="at">newdata =</span> X) <span class="sc">+</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>  stats<span class="sc">::</span><span class="fu">rnorm</span>(n_sample, <span class="dv">0</span>, <span class="fl">0.1</span>)</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co"># Store all as a data frame</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">cbind</span>(X, Y))</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="fu">head</span>(data)</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">#&gt;           V1           V2         V3          Y</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co">#&gt; 1  1.3709584  1.029140719  2.3250585 -1.7547416</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="co">#&gt; 2 -0.5646982  0.914774868  0.5241222 -3.7107357</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co">#&gt; 3  0.3631284 -0.002456267  0.9707334  1.3609395</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="co">#&gt; 4  0.6328626  0.136009552  0.3769734  2.4608270</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a><span class="co">#&gt; 5  0.4042683 -0.720153545 -0.9959334 -0.6141076</span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="co">#&gt; 6 -0.1061245 -0.198124330 -0.5974829 -0.7455793</span></span></code></pre></div>
<p>Then we will scale the data to have everything in the <span class="math inline">\([-1,1]\)</span> interval and divide it in train
and test.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Data scaling to [-1,1]</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>maxs <span class="ot">&lt;-</span> <span class="fu">apply</span>(data, <span class="dv">2</span>, max)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>mins <span class="ot">&lt;-</span> <span class="fu">apply</span>(data, <span class="dv">2</span>, min)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">scale</span>(data, <span class="at">center =</span> mins <span class="sc">+</span> (maxs <span class="sc">-</span> mins) <span class="sc">/</span> <span class="dv">2</span>, <span class="at">scale =</span> (maxs <span class="sc">-</span> mins) <span class="sc">/</span> <span class="dv">2</span>))</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co"># Divide in train (0.75) and test (0.25)</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(data), <span class="fu">round</span>(<span class="fl">0.75</span> <span class="sc">*</span> <span class="fu">nrow</span>(data)))</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>train <span class="ot">&lt;-</span> data[index, ]</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>test <span class="ot">&lt;-</span> data[<span class="sc">-</span>index, ]</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>train_x <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(train[,<span class="sc">-</span>(p<span class="sc">+</span><span class="dv">1</span>)])</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>train_y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(train[,(p<span class="sc">+</span><span class="dv">1</span>)])</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>test_x <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(test[,<span class="sc">-</span>(p<span class="sc">+</span><span class="dv">1</span>)])</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>test_y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(test[,(p<span class="sc">+</span><span class="dv">1</span>)])</span></code></pre></div>
</div>
<div id="original-neural-network" class="section level2">
<h2>Original neural network</h2>
<p>With our simulated data ready, we can train our neural network. The
method is expected to be applied to a given trained densely connected
feed forward neural network (NN from now on), also referred as
multilayer perceptron (MLP). Therefore, as explained before, any method
can be used to train the NN as <code>nn2poly</code> only needs the
weights and activation functions.</p>
<p>Here we will use <code>keras</code>/<code>tensorflow</code> to train
it, but we will manually build the needed object with the weights and
activation functions that has to be fed to the <code>nn2poly</code>
algorithm <strong>to show how to do it as if it was trained with any
other framework</strong>. However, recall that
<code>keras</code>/<code>tensorflow</code> and
<code>luz</code>/<code>torch</code> models have specific support in
<code>nn2poly</code> with a more user-friendly approach than the default
case covered here where we manually build the weights and activation
functions object. For more information on the supported frameworks refer
to <code>vignette(&quot;nn2poly-02-supported-DL-frameworks&quot;)</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co"># This sets all needed seeds</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>tensorflow<span class="sc">::</span><span class="fu">set_random_seed</span>(<span class="dv">42</span>)</span></code></pre></div>
<p>First, we build the model.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>nn <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>nn <span class="sc">%&gt;%</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>,</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>                  <span class="at">activation =</span> <span class="st">&quot;tanh&quot;</span>,</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>                  <span class="at">input_shape =</span> p)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>nn <span class="sc">%&gt;%</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>,</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>                  <span class="at">activation =</span> <span class="st">&quot;tanh&quot;</span>)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>nn <span class="sc">%&gt;%</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>,</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>                  <span class="at">activation =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>nn</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co">#&gt; Model: &quot;sequential_9&quot;</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co">#&gt; ________________________________________________________________________________________________________________________________________________________</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a><span class="co">#&gt;  Layer (type)                                                       Output Shape                                                 Param #                </span></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a><span class="co">#&gt; ========================================================================================================================================================</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a><span class="co">#&gt;  dense_27 (Dense)                                                   (None, 10)                                                   40                     </span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a><span class="co">#&gt;  dense_28 (Dense)                                                   (None, 10)                                                   110                    </span></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a><span class="co">#&gt;  dense_29 (Dense)                                                   (None, 1)                                                    11                     </span></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a><span class="co">#&gt; ========================================================================================================================================================</span></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a><span class="co">#&gt; Total params: 161</span></span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a><span class="co">#&gt; Trainable params: 161</span></span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a><span class="co">#&gt; Non-trainable params: 0</span></span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a><span class="co">#&gt; ________________________________________________________________________________________________________________________________________________________</span></span></code></pre></div>
<p>Compile the model:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">compile</span>(nn,</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>        <span class="at">loss =</span> <span class="st">&quot;mse&quot;</span>,</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>        <span class="at">optimizer =</span> <span class="fu">optimizer_adam</span>(),</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>        <span class="at">metrics =</span> <span class="st">&quot;mse&quot;</span>)</span></code></pre></div>
<p>And train it:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>history <span class="ot">&lt;-</span> <span class="fu">fit</span>(nn,</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>               train_x,</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>               train_y,</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>               <span class="at">verbose =</span> <span class="dv">0</span>,</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>               <span class="at">epochs =</span> <span class="dv">250</span>,</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>               <span class="at">validation_split =</span> <span class="fl">0.3</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>)</span></code></pre></div>
<p>We can visualize the training process:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">plot</span>(history)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /></p>
<p>And we can also visualize the NN predictions vs the original Y
values.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Obtain the predicted values with the NN to compare them</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>prediction_NN <span class="ot">&lt;-</span> <span class="fu">predict</span>(nn, test_x)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">#&gt; 4/4 - 0s - 71ms/epoch - 18ms/step</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co"># Diagonal plot implemented in the package to quickly visualize and compare predictions</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>nn2poly<span class="sc">:::</span><span class="fu">plot_diagonal</span>(<span class="at">x_axis =</span>  prediction_NN, <span class="at">y_axis =</span>  test_y, <span class="at">xlab =</span> <span class="st">&quot;NN prediction&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Original Y&quot;</span>)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /></p>
<blockquote>
<p><em>Note</em>: Recall that the NN performance is not addressed by
<code>nn2poly</code>, meaning that this performance could be either good
or bad and <code>nn2poly</code>’s goal would still be to represent the
NN behavior and predict as good or as bad as the NN.</p>
</blockquote>
</div>
<div id="building-the-needed-input-for-default-nn2poly" class="section level2">
<h2>Building the needed input for default <code>nn2poly</code></h2>
<p>Once the NN has been trained, using any chosen method by the user,
the default version of using <code>nn2poly</code> requires to set up the
weight matrices and activation functions from the neural network in the
expected input form. This should be a list of matrices such that:</p>
<ul>
<li>There is a weight matrix per layer. The weights matrices should be
of dimension <span class="math inline">\(((1+input) * output)\)</span>
where the first row corresponds to the bias vector, and the rest of the
rows correspond to each of the ordered vector weights associated to each
neuron input.</li>
<li>The name of each element in the list (i.e. each weight matrix) has
to be the name of the activation function employed at that layer.
Currently supported activation functions are
<code>&quot;tanh&quot;, &quot;sigmoid&quot;, &quot;softplus&quot;, &quot;linear&quot;</code>.</li>
<li>Then, the total size of the list has to be equal to the number of
hidden layers plus one.</li>
</ul>
<p>In particular, the <code>keras</code> framework by default separates
kernel weights matrices of dimension (input * output) and bias vectors
(1 * output), so we need to add the bias as the first row of a matrix
((1+input) * output).</p>
<blockquote>
<p><em>Note</em>: Please note again that
<code>keras</code>/<code>tensorflow</code> and
<code>luz</code>/<code>torch</code> models have specific support in
<code>nn2poly</code> with a more user-friendly approach than manually
building the weights and activation functions list. For more information
on the supported frameworks refer to
<code>vignette(&quot;nn2poly-02-supported-DL-frameworks&quot;)</code>.</p>
</blockquote>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>keras_weights <span class="ot">&lt;-</span> keras<span class="sc">::</span><span class="fu">get_weights</span>(nn)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co"># Due to keras giving weights separated from the bias, we have twice the</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co"># elements that we want:</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(keras_weights)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>nn_weights <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">&quot;list&quot;</span>, <span class="at">length =</span> n)</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>  nn_weights[[i]] <span class="ot">&lt;-</span> <span class="fu">rbind</span>(keras_weights[[<span class="dv">2</span><span class="sc">*</span>i]], keras_weights[[<span class="dv">2</span><span class="sc">*</span>i<span class="dv">-1</span>]])</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>}</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="co"># The activation functions stored as strings:</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>af_string_names <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;tanh&quot;</span>,<span class="st">&quot;tanh&quot;</span>, <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>weights_object <span class="ot">&lt;-</span> nn_weights</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a><span class="fu">names</span>(weights_object) <span class="ot">&lt;-</span> af_string_names</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>weights_object</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="co">#&gt; $tanh</span></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="co">#&gt;            [,1]       [,2]      [,3]       [,4]        [,5]       [,6]       [,7]        [,8]        [,9]        [,10]</span></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a><span class="co">#&gt; [1,]  0.2468006 -0.1615576 0.4128721 -0.2022066  0.04867206 -0.3397017 -0.1973533 -0.08864177 -0.06979843 -0.359030366</span></span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a><span class="co">#&gt; [2,]  0.2653632  0.1291278 0.1464561  0.5171605 -0.47153816  0.1952459  0.6991890 -0.34414759 -0.01077842  0.006373413</span></span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a><span class="co">#&gt; [3,] -0.7783106 -0.1182964 0.8215331  0.0756740  0.06914742  0.7492308 -0.8363205 -0.46379340  0.04437404 -0.698476076</span></span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a><span class="co">#&gt; [4,] -0.7159964  0.5072741 0.6033612 -0.4585148  0.49232438 -0.7474106  0.1091831  0.34101799  0.04305385 -0.571668506</span></span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a><span class="co">#&gt; $tanh</span></span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a><span class="co">#&gt;              [,1]          [,2]        [,3]        [,4]        [,5]       [,6]        [,7]        [,8]        [,9]        [,10]</span></span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a><span class="co">#&gt;  [1,] -0.06682093  1.354177e-02  0.41062176  0.06204464  0.08612972  0.2199472  0.07406761  0.16231309  0.08528626  0.074458212</span></span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a><span class="co">#&gt;  [2,]  0.61209673 -1.587261e-01  0.33286688  0.16685191  0.25638032 -0.2960541  0.06451954 -0.04405669 -0.57139808 -0.314788640</span></span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a><span class="co">#&gt;  [3,] -0.24969149 -5.748887e-02 -0.46696794  0.12622431 -0.03608320 -0.3931088  0.28291187  0.24243380 -0.47687724 -0.002060457</span></span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a><span class="co">#&gt;  [4,]  0.38323382  4.771161e-01  0.11585876  0.44199020  0.16203447  0.6357560  0.01491554 -0.29491946  0.09033196 -0.017912282</span></span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a><span class="co">#&gt;  [5,] -0.24755152  6.043483e-06  0.41534948  0.27495798 -0.46539015 -0.3829005 -0.53592098 -0.42729110 -0.48928314 -0.197884247</span></span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a><span class="co">#&gt;  [6,] -0.26591998  5.250556e-01 -0.10562975  0.37414369  0.26212201  0.4499114 -0.41681677 -0.25272584 -0.28060704 -0.249755934</span></span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a><span class="co">#&gt;  [7,]  0.49481559  1.359816e-01  0.67004895 -0.15929574  0.16280667  0.4475754 -0.20691858  0.40582910 -0.11089712 -0.387193263</span></span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a><span class="co">#&gt;  [8,]  0.40330765 -4.343324e-01 -0.92225003 -0.15942611  0.01812540  0.2977643 -0.04585903 -0.37514219  0.24891976 -0.395170867</span></span>
<span id="cb11-35"><a href="#cb11-35" tabindex="-1"></a><span class="co">#&gt;  [9,]  0.51166564  1.184353e-01 -0.82071930 -0.02945352  0.31787610  0.2762571  0.48814669 -0.39470875  0.01584071 -0.538033605</span></span>
<span id="cb11-36"><a href="#cb11-36" tabindex="-1"></a><span class="co">#&gt; [10,]  0.27744713 -1.118216e-01  0.02931483  0.35466376  0.24984393 -0.1250943 -0.32097501  0.09834206 -0.06148605 -0.403377086</span></span>
<span id="cb11-37"><a href="#cb11-37" tabindex="-1"></a><span class="co">#&gt; [11,] -0.50523925  4.479433e-01 -0.55034703  0.48515356 -0.03854835 -0.8001245  0.15069254 -0.20994137  0.23820342  0.375222772</span></span>
<span id="cb11-38"><a href="#cb11-38" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-39"><a href="#cb11-39" tabindex="-1"></a><span class="co">#&gt; $linear</span></span>
<span id="cb11-40"><a href="#cb11-40" tabindex="-1"></a><span class="co">#&gt;              [,1]</span></span>
<span id="cb11-41"><a href="#cb11-41" tabindex="-1"></a><span class="co">#&gt;  [1,] -0.07325488</span></span>
<span id="cb11-42"><a href="#cb11-42" tabindex="-1"></a><span class="co">#&gt;  [2,]  0.92378414</span></span>
<span id="cb11-43"><a href="#cb11-43" tabindex="-1"></a><span class="co">#&gt;  [3,] -0.08239315</span></span>
<span id="cb11-44"><a href="#cb11-44" tabindex="-1"></a><span class="co">#&gt;  [4,] -0.32572412</span></span>
<span id="cb11-45"><a href="#cb11-45" tabindex="-1"></a><span class="co">#&gt;  [5,] -0.43841833</span></span>
<span id="cb11-46"><a href="#cb11-46" tabindex="-1"></a><span class="co">#&gt;  [6,] -0.08093655</span></span>
<span id="cb11-47"><a href="#cb11-47" tabindex="-1"></a><span class="co">#&gt;  [7,]  0.59904134</span></span>
<span id="cb11-48"><a href="#cb11-48" tabindex="-1"></a><span class="co">#&gt;  [8,] -0.65850627</span></span>
<span id="cb11-49"><a href="#cb11-49" tabindex="-1"></a><span class="co">#&gt;  [9,] -0.04606140</span></span>
<span id="cb11-50"><a href="#cb11-50" tabindex="-1"></a><span class="co">#&gt; [10,] -0.79061949</span></span>
<span id="cb11-51"><a href="#cb11-51" tabindex="-1"></a><span class="co">#&gt; [11,] -0.89735550</span></span></code></pre></div>
</div>
<div id="polynomial-obtained-with-nn2poly-from-weights-and-activation-functions" class="section level2">
<h2>Polynomial obtained with <code>nn2poly</code> from weights and
activation functions</h2>
<p>After setting up the NN information in our desired input shape, we
are ready to employ <code>nn2poly</code>. The only last parameter that
we need to specify is the final order of our desired polynomial,
<code>max_order</code>. It should be an integer value denoting the
maximum order of the terms computed in the polynomial. Usually 2 or 3
should be enough in real data and default value is set up to 2,
capturing pairwise interactions. Note that higher orders suppose an
explosion in the possible combinations of variables and therefore the
number of terms in the polynomial.</p>
<p>In this example we will set <code>max_order = 3</code> and obtain our
final polynomial:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>final_poly <span class="ot">&lt;-</span> <span class="fu">nn2poly</span>(<span class="at">object =</span> weights_object,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>                      <span class="at">max_order =</span> <span class="dv">3</span>)</span></code></pre></div>
<p>We can have a glimpse at how the coefficients of the polynomial are
stored. Note that the structure is the same as explained for the
polynomial that generated the data, as a list with labels and values. In
this case, the obtained polynomial is up to order 3.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>final_poly</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co">#&gt; $labels</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co">#&gt; $labels[[1]]</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co">#&gt; [1] 0</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co">#&gt; $labels[[2]]</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">#&gt; $labels[[3]]</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co">#&gt; [1] 2</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="co">#&gt; $labels[[4]]</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a><span class="co">#&gt; [1] 3</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a><span class="co">#&gt; $labels[[5]]</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a><span class="co">#&gt; [1] 1 1</span></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a><span class="co">#&gt; $labels[[6]]</span></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a><span class="co">#&gt; [1] 1 2</span></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a><span class="co">#&gt; $labels[[7]]</span></span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a><span class="co">#&gt; [1] 1 3</span></span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a><span class="co">#&gt; $labels[[8]]</span></span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a><span class="co">#&gt; [1] 2 2</span></span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a><span class="co">#&gt; $labels[[9]]</span></span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a><span class="co">#&gt; [1] 2 3</span></span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a><span class="co">#&gt; $labels[[10]]</span></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a><span class="co">#&gt; [1] 3 3</span></span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a><span class="co">#&gt; $labels[[11]]</span></span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a><span class="co">#&gt; [1] 1 1 1</span></span>
<span id="cb13-35"><a href="#cb13-35" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-36"><a href="#cb13-36" tabindex="-1"></a><span class="co">#&gt; $labels[[12]]</span></span>
<span id="cb13-37"><a href="#cb13-37" tabindex="-1"></a><span class="co">#&gt; [1] 1 1 2</span></span>
<span id="cb13-38"><a href="#cb13-38" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-39"><a href="#cb13-39" tabindex="-1"></a><span class="co">#&gt; $labels[[13]]</span></span>
<span id="cb13-40"><a href="#cb13-40" tabindex="-1"></a><span class="co">#&gt; [1] 1 1 3</span></span>
<span id="cb13-41"><a href="#cb13-41" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-42"><a href="#cb13-42" tabindex="-1"></a><span class="co">#&gt; $labels[[14]]</span></span>
<span id="cb13-43"><a href="#cb13-43" tabindex="-1"></a><span class="co">#&gt; [1] 1 2 2</span></span>
<span id="cb13-44"><a href="#cb13-44" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-45"><a href="#cb13-45" tabindex="-1"></a><span class="co">#&gt; $labels[[15]]</span></span>
<span id="cb13-46"><a href="#cb13-46" tabindex="-1"></a><span class="co">#&gt; [1] 1 2 3</span></span>
<span id="cb13-47"><a href="#cb13-47" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-48"><a href="#cb13-48" tabindex="-1"></a><span class="co">#&gt; $labels[[16]]</span></span>
<span id="cb13-49"><a href="#cb13-49" tabindex="-1"></a><span class="co">#&gt; [1] 1 3 3</span></span>
<span id="cb13-50"><a href="#cb13-50" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-51"><a href="#cb13-51" tabindex="-1"></a><span class="co">#&gt; $labels[[17]]</span></span>
<span id="cb13-52"><a href="#cb13-52" tabindex="-1"></a><span class="co">#&gt; [1] 2 2 2</span></span>
<span id="cb13-53"><a href="#cb13-53" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-54"><a href="#cb13-54" tabindex="-1"></a><span class="co">#&gt; $labels[[18]]</span></span>
<span id="cb13-55"><a href="#cb13-55" tabindex="-1"></a><span class="co">#&gt; [1] 2 2 3</span></span>
<span id="cb13-56"><a href="#cb13-56" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-57"><a href="#cb13-57" tabindex="-1"></a><span class="co">#&gt; $labels[[19]]</span></span>
<span id="cb13-58"><a href="#cb13-58" tabindex="-1"></a><span class="co">#&gt; [1] 2 3 3</span></span>
<span id="cb13-59"><a href="#cb13-59" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-60"><a href="#cb13-60" tabindex="-1"></a><span class="co">#&gt; $labels[[20]]</span></span>
<span id="cb13-61"><a href="#cb13-61" tabindex="-1"></a><span class="co">#&gt; [1] 3 3 3</span></span>
<span id="cb13-62"><a href="#cb13-62" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-63"><a href="#cb13-63" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-64"><a href="#cb13-64" tabindex="-1"></a><span class="co">#&gt; $values</span></span>
<span id="cb13-65"><a href="#cb13-65" tabindex="-1"></a><span class="co">#&gt;               [,1]</span></span>
<span id="cb13-66"><a href="#cb13-66" tabindex="-1"></a><span class="co">#&gt;  [1,] -0.152201327</span></span>
<span id="cb13-67"><a href="#cb13-67" tabindex="-1"></a><span class="co">#&gt;  [2,]  0.750790396</span></span>
<span id="cb13-68"><a href="#cb13-68" tabindex="-1"></a><span class="co">#&gt;  [3,]  0.096754449</span></span>
<span id="cb13-69"><a href="#cb13-69" tabindex="-1"></a><span class="co">#&gt;  [4,] -0.055312169</span></span>
<span id="cb13-70"><a href="#cb13-70" tabindex="-1"></a><span class="co">#&gt;  [5,]  0.087070907</span></span>
<span id="cb13-71"><a href="#cb13-71" tabindex="-1"></a><span class="co">#&gt;  [6,]  0.184542875</span></span>
<span id="cb13-72"><a href="#cb13-72" tabindex="-1"></a><span class="co">#&gt;  [7,]  0.056719718</span></span>
<span id="cb13-73"><a href="#cb13-73" tabindex="-1"></a><span class="co">#&gt;  [8,]  0.117868180</span></span>
<span id="cb13-74"><a href="#cb13-74" tabindex="-1"></a><span class="co">#&gt;  [9,] -2.316887421</span></span>
<span id="cb13-75"><a href="#cb13-75" tabindex="-1"></a><span class="co">#&gt; [10,] -0.111600389</span></span>
<span id="cb13-76"><a href="#cb13-76" tabindex="-1"></a><span class="co">#&gt; [11,] -0.106978125</span></span>
<span id="cb13-77"><a href="#cb13-77" tabindex="-1"></a><span class="co">#&gt; [12,]  0.335722744</span></span>
<span id="cb13-78"><a href="#cb13-78" tabindex="-1"></a><span class="co">#&gt; [13,]  0.007464716</span></span>
<span id="cb13-79"><a href="#cb13-79" tabindex="-1"></a><span class="co">#&gt; [14,]  0.580397844</span></span>
<span id="cb13-80"><a href="#cb13-80" tabindex="-1"></a><span class="co">#&gt; [15,] -0.072672555</span></span>
<span id="cb13-81"><a href="#cb13-81" tabindex="-1"></a><span class="co">#&gt; [16,]  0.064910409</span></span>
<span id="cb13-82"><a href="#cb13-82" tabindex="-1"></a><span class="co">#&gt; [17,]  0.274290026</span></span>
<span id="cb13-83"><a href="#cb13-83" tabindex="-1"></a><span class="co">#&gt; [18,] -0.474785464</span></span>
<span id="cb13-84"><a href="#cb13-84" tabindex="-1"></a><span class="co">#&gt; [19,] -0.242252638</span></span>
<span id="cb13-85"><a href="#cb13-85" tabindex="-1"></a><span class="co">#&gt; [20,]  0.013870973</span></span>
<span id="cb13-86"><a href="#cb13-86" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-87"><a href="#cb13-87" tabindex="-1"></a><span class="co">#&gt; attr(,&quot;class&quot;)</span></span>
<span id="cb13-88"><a href="#cb13-88" tabindex="-1"></a><span class="co">#&gt; [1] &quot;nn2poly&quot;</span></span></code></pre></div>
</div>
<div id="predictions-using-the-obtained-polynomial" class="section level2">
<h2>Predictions using the obtained polynomial</h2>
<p>With the obtained polynomial coefficients, we can use them to predict
the response variable <span class="math inline">\(Y\)</span> using the
polynomial. This can be done using <code>predcit()</code> on the output
of <code>nn2poly</code> (object with class <code>&quot;nn2poly&quot;</code>)
together with the desired values for the predictor variables.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co"># Obtain the predicted values for the test data with our polynomial</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>prediction_poly <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="at">object =</span> final_poly,</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>                           <span class="at">newdata =</span> test_x)</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co"># In this case the output is a vector of length equal to the rows of test_x,</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co"># as we are predicting the output of out final polynomial for each observation.</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="fu">length</span>(prediction_poly)<span class="sc">==</span><span class="fu">nrow</span>(test_x)</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span></code></pre></div>
<p>Another option available is to evaluate the monomials of the obtained
polynomial separately, which may be useful when trying to analyze the
contribution of each term to the final output of the model, specially
when comparing interactions of variables. This can be done by passing
the option <code>monomials=TRUE</code> to the <code>predict()</code>
function.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="co"># Obtain the predicted values for the test data with our polynomial</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>prediction_monomials <span class="ot">&lt;-</span> <span class="fu">predict</span>(<span class="at">object =</span> final_poly,</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>                                <span class="at">newdata =</span> test_x,</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>                                <span class="at">monomials =</span> <span class="cn">TRUE</span>)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="co"># In this case, the output is a 3D array, where the last dimension corresponds </span></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="co"># to the number of output polynomials (in this example 1), and each matrix</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="co"># represented by the first two dimensions has rows equal to the rows in</span></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a><span class="co"># test_x, and columns equal to the rows in poly$values, corresponding to a </span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="co"># column for each monomial (or term) in the polynomial.</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="fu">dim</span>(prediction_monomials)</span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a><span class="co">#&gt; [1] 125  20   1</span></span></code></pre></div>
</div>
<div id="visualizing-the-results" class="section level2">
<h2>Visualizing the results</h2>
<blockquote>
<p><em>Note</em>: Once again note that, in order to avoid asymptotic
behavior of the method, it is important to impose some kind of
constraints when training the neural network weights, something which we
are not doing here to simplify this first example. Details on how to do
this depend on the chosen deep learning framework and are covered in the
next vignettes.</p>
</blockquote>
<p>It is advisable to always check that the predictions obtained with
the new polynomial are close to the original NN predictions (and in case
they differ, we can also try to find why by checking the Taylor
expansions). To help with that, a couple of functions are included that
allow us to plot the results.</p>
<p>A simple plot comparing the polynomial and NN predictions can be
obtained with <code>nn2poly:::plot_diagonal()</code>, where the red
diagonal line represents where a perfect relationship between the NN and
the polynomial predictions would be obtained. In this example, as the
theoretical weight constraints have not been imposed, we can observe how
the approximation is not perfect.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>nn2poly<span class="sc">:::</span><span class="fu">plot_diagonal</span>(<span class="at">x_axis =</span>  prediction_NN, <span class="at">y_axis =</span>  prediction_poly, <span class="at">xlab =</span> <span class="st">&quot;NN prediction&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Polynomial prediction&quot;</span>)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /></p>
<p>We can also plot the <span class="math inline">\(n\)</span> most
important coefficients in absolute value to compare which variables or
interactions are more relevant in the polynomial. Note that, as data
should be scaled to the <span class="math inline">\([-1,1]\)</span>
interval, interactions of order 2 or higher would usually need a higher
absolute value than the lower order coefficients to be more
relevant.</p>
<p>In this case we can see how the two most important obtained
coefficients are <code>2,3</code> and <code>1</code>, precisely the two
terms appearing in the original polynomial <span class="math inline">\(4x_1 - 3 x_2x_3\)</span>. However, other
interactions of order 3 appear to be also relevant, which is caused by
the Taylor expansions not being controlled as we have not imposed
constraints on the neural network weights training.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">plot</span>(final_poly, <span class="at">n=</span><span class="dv">8</span>)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /></p>
<p>Another convenient plot to show how the algorithm is affected by each
layer can be obtained with
<code>nn2poly:::plot_taylor_and_activation_potentials()</code>, where
the activation potentials at each neuron are computed and presented over
the Taylor expansion approximation of the activation function at each
layer.</p>
<p>In this case, as we have not used constraints in the NN training, the
activation potentials are not strictly centered around zero.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>nn2poly<span class="sc">:::</span><span class="fu">plot_taylor_and_activation_potentials</span>(<span class="at">object =</span> nn,</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>                                                <span class="at">data =</span> train,</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>                                                <span class="at">max_order =</span> <span class="dv">3</span>,</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>                                                <span class="at">constraints =</span> <span class="cn">FALSE</span>)</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="co">#&gt; [[1]]</span></span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /></p>
<pre><code>#&gt; 
#&gt; [[2]]</code></pre>
<p><img role="img" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfgAAAH4CAMAAACR9g9NAAABBVBMVEUAAAAAADoAAGYAAP8AOmYAOpAAZAAAZmYAZrY6AAA6ADo6AGY6OgA6Ojo6OmY6OpA6ZmY6ZpA6ZrY6kNtNTU1NTW5NbqtNjshmAABmADpmAGZmOgBmOmZmOpBmZgBmZjpmZmZmZrZmtv9uTU1uq+SObquOjsiOq+SOyP+QOgCQOjqQOmaQZjqQZpCQkDqQkLaQtpCQ2/+Q7pCrbk2r5P+2ZgC2Zjq2Zma2tma2tv+2/9u2//++vr7Ijk3Ijm7Iq47IyP/bkDrbtmbb25Db2//b/7bb/9vb///kq27kq47k///r6+v/AAD/tmb/yI7/25D/29v/5Kv//7b//8j//9v//+T///8bzOSHAAAACXBIWXMAAAsSAAALEgHS3X78AAAXCUlEQVR4nO3d/WPbxn0GcNisVamZ68x0EzVtt45NWttb28kxk2yavWlZq8QCrURW8P//KbsXgATxdq84fO/ueX6gJPDLA8QPDwRJ8K6okCxTLL0ByDIBfKYBfKYBfKYhC39ycrL0JiQdqvAnJ68gP2da8LdPrqcq718UxalZ43e/a7XYNH+0cDQnr169AvyM0Ye/OmX2G6PGB1tUrEaGu0N+zvThr3jH3q6randa7fjvt7/8zcNLWXK1rks/Pue9n5XKBbdnBSsRf8qr+O5hzS4efctvLJq8ffItv4ov/PuL5oZjqeEhP1t68Ozy7rPL248uWffmS7ab219c1BXsirr0o0tZdPdrfh2/vDqVf8qr2IOGFzy55jeum3zyrbzVk2t57dRmSXh0+fnS7/Gs9z64kOqsw7Ouud83S+W69P7lBfNjj4v9LeWf8irWyKlYLq4STTJ4eRVbeKY4WqjdAT9fevC7h6Ib707Zbn13eljOfu57vhpeYG9qeNlkC15eO75RjTvk50sfnj2zP7hgvfuXl5y63uFXYvfeLuWE7V397tG3clcvrrriD4J1Ay+abMHLa8c3qgUP+ZnShj9jO/bTu/Pi5+cbcRBf1Qd3En4r9vvyubnu1uygbdPcVB7cbZqrWPWj67vzRwy7kk028Gzhtbh2fKMO8Ojyc2XsDRyxux7K15MHZV7Sckefnysj8Luxo6/7v863LU2O4NHn5wnFt2yP4SE/SwjCd9yxs58lEcCjy88RevA9d3T5ORIDPLr8DCEHP+AO+RkSCTzkfYca/MkgPLq895CDH3RHl/eeSODR5X2HGPyYO+R9Jxp4yPsNLfgJd8D7DSn4kUN6yM8QWvBT7jiy95qI4NHlfYYSvMIdXd5nYoJHl/cYQvBKd8h7TGTwkPcVOvAa7pD3FzLwWu6Q9xYq8NPv3YDee4jA67tD3k9owJu4g95LKMAbskPeRwjAm7u/wit65ywNf2LFjk7vnIXhbdmFPOgdsii8A3tN32TJ/yLOLAnv6D78GOivBI+LoSwH75F9+CFQp1622P9JNEvBWx/UuTweFvpfSSYs/FE/DJ6jHUHQ/5tg5oTv7XWX8R5M9g8AT/ADxvnep1Fk6TdwkIUC+EwD+EwD+ExjBH8ToiLISjQqEg/gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gMw3gM02e8EUBeJPiROCLAj0+Q/iCuwM+O/ii0Gwj8eQGX7sDPi/4olBVZJOs4A/ugM8JvuUO+Hzgi0JVkVWygT92B3wu8B13wGcC33UHfB7w/f8S8CbFkcL3urtWG4knA/ghd8CnDz/oDvjk4YfdAZ86/Ig74BOHH3MHfOrw9m0knrThx/87wJsUxwY/8c8B3qQ4MvjRJ3itNhJPwvBT7oBPF37SHfDJwk+7Az5VeIU74JOFd24j8SQKr/y3AG9SHA28akcP+DTh1e6ATxPex4YmHg34m9hSGFXPfx+TTII9nu3o0eOVSQ9eb9gDwJsUxwHvZzNST3LwmuNdAN6kOAJ4+UoO8MokB+9rM1JPYvDaI9wA3qSYPLz+CDeANymmD+9vM1JPUvAF4LWTErzJmFaANymmDu9zM1JPQvBGg5kB3qSYOLzXzUg96cAXygqztSSeZOALwBslHXjPm5F6UoE/dPiyieNaEk8y8PVP6X0jfpuiB7xJMV34usM31jf1X+P0gDcpJgwvLvfQTcW4POBNisnCi/+ipbyvGJUHvEkxafi28aFiTB7wJsVU4bvu7YoRecCbFBOGP/ZtVwB+MCnAiw4/XjEoD3iTYprw/KVcOVExuLMHvEkxUfi+7XHFkDzgTYpJwrMO35PttAH4fhKAH4DtwvflAW9STBGed3hlG4DvJX54rf6s2ifkl9jhBzv8ALziKCC/RA8/+DK93wbgO4kcvig0X6VPv+DLMLHDa78vB/jjxA0/0uEH4Sfe1M0xkcMbfPYG+KNEDc86vH4b45/fZZm44Y1OswB8O5HDm7QB+HZihh/t8CNtjJyjk2fihjdrA/CtRAw/7j7WxuDpmJkG8JnGCH6lrAgIP+E+Cn+4ifpfSTxZwVeA3yda+Cl3NfwKu3qT4hulPHX45kaAjxZ+8uvvo20AvkkP/qcvn31a//zV6851hOAnOzzg1enBv/+8evOc/fzwx34xIfjpAS/G26hvBvge/PevuX1V/fiHZ5+8E0taE/es/M4aZJ+itLyhvF37/wh9jxNJD/5tDc8ufvxT57ob5XF9qB5vPcKNvN0Kb+CM9viq2v/chwz89DP8ZBviloAff47/7nn1/nnnOjLwig6vgl/hLduRo/oPX7xrju7boQNv3wbgZUw/pFHIh4FX7ekn2ygBzxMlvMod8OrECK/s8Ar4ldZaEk+M8KpDO0UbJeArixMxpuXDwLutBPA8EcKr9/SAVydC+NJxJSvAVzHCF87wpc5mpB7zky0n5QPAl64rATxPdPAF4L0kOvjSdSXsKV6rjcSTIbxmG4nH4gsVU/Kzw5eA95Po4J1XAniR7OBXshXAmxQvD18C3lNsvjQ5IT87vPNKAC8TF3zhCV7nbd/EExd86bySetsBbwU/Lg/4WGI1MMJS8KU/ePVHu4knLnj3layUFZkkM/iVsiKX2I2BMyo/K3x35liLNgDfBPCZJiL4wh1+pazIJpbwY/JzwpfKCmUbgN/Hcpw7wMeeeOBLd/gV4PeJCN59JStlRT6xHdJ0RB7wsSQa+BLwXmMNPyw/I7z7SlbKioxiPXo14ONOLPBmkwwAXhl7+EF5yvArZUVOsZ+oAPBRJxJ4wxmkAK9MPvArZUVWcZiTZkge8LEkDnjTeWEBr4wL/IA8XfiVsiKvuEw/BviIEwV8qaxQtwH44zjB9+XJwnc3FfAmxd17KxB898sPgPeQTOB7Wwp4k+IevMX9CXga0YCfmNonyOREtvMOtTOxofPfxyTjNpt0kB7f+36j+UpsnpMSj+M04ubHTICnEfrw/S80G6/E6nVn4nGFN35fZBF4i81IPY7w5m+IAZ5GyMMPDF1huhK7jxETjyu88aedgKeRDOAHTwsFvEnxILzhqWyG8EODFJnCW21G6nGGNz2HMTi87XngiccDvNn3FMLD221G6nGHN/yCihn84HB0gPeQ5OGNv9Z7++R6uvH7FxvlBtCPB3izbx8DnkZoww8PPGqyEvOhO2r4XVGc8suHf9nI328/PudLroqf/QbwdUyGlokEnl9uN3e/vrg738jfbz+6vPvskl3engG+zuHAnhq8xYB8Ep518qJYS/L97/cvL67WFVui3AD68QJvMmCkCfzIGNNB4E+b3xl88zvgu9l3ec/wlk3sK2xGW6539b+4YAdx9a5e/C7h+Q7/HPD7pAR/VvBjuf3B3T81B3cCnh3cPfgHwO/TdHmv8GOzCWivxGkOlTocO8V4gq9mgbdtwhv83Tk7qtOqjC7e4FeqCnUb3QJXeLcJ8hKPL/jKP/zovDGaK5mYMwnw/uClvFd46yZqeKfNSD0e4VeqCnUbRwWO8JPugPcHX3mGH58hTGslkzt6wHuFX/mFt29CwDtuRurxCM/lycAr3AHvE76iA6/Y0QPeM/zKH/zEHKA68M6bkXq8wquOqLTa8AHvYTNSj194DfkQ8D4ef53wN2+Lh5fdxbdnvXd0f7jexfAur2d4D/tYWTA123OQZ5xe7n43cC7eVe+DusEygvEN73447Qzv/OKiOEqzlIvuHj/8Zs20Wf9/JD61P3twseMLdnx3cP+CXVwVp7s1++3R9W5oF0Em/uFdX0C7w3t5O6EXAX9aCWfW0eX+XP5yxU/SYRdrVsDKdusrtmwtlhmvJlS8wzu/ZSYKptzDvIHYi4BfS+etOFejasHXDwdRtlt/dVHdPhXLjFcTKv7hFfJzw/v6rKiXA/x2sweV8NtNo3/75G+HHp8bvOPnobxg/H16VROrueHZ0/vjzf4EDSYrFkjkbfHg4v7F/jk+O/hJeT14283wdyJQ6pkFfkp+TnifJ/umnnngXWaYt4f3+r2O1DMX/Ki8Dvy0+1gTRpOEA96k2Oj+tJ191hJ+1V4f4JWZD/6YQr8NO3jvQ/Gknhnhh+k14BXuA010VwR4ZWaFH6KfAd5iJYCfGd6iM5rCW+1WAD87vJAxOe66UbkfH0HONdNp6unB//Tls0/bP9uxvj9XB3x/8KsRdZ2VuJ+IoX22RbeQyIkaPfj3n1dvnrd+tuN0f65kfMDXTVlthnZFN50zLGz1qJyo0YP//jU3P/ysqv9i4ZO3ePnJvPjPleNPb9szNCdNeZRmKRe7PSseXGzXfMCM5pOYx3w3IJbvPj57eCkvHj/8T37l9rTaskK+7Bu2uxBVVE7U6MG/rcHf7uEP8dGRlBXKDh9mM3rh8D9c89NvPru8f3lxONuiquTyHf9ATl6cVuLKavt7fuYGW3bFT8qQtyZyooZGjz8ke3jWU4sNHwHraXU426Kq5HL+cfzT5kJcyQdU4fD16RuiisqJGuGe4zUrpj+KD7YZ/XB4BrbdMLOvuGdztgWLWC7Oy5IXa9nj71/++5PrA7youiNyosbwUf2HL955Pao3qCjDsFqeiFEUv2fSX/0jPyejOduiquTy3eOCP73zizXfBzz6+wtG++h/9/CiisqJGgFex5tVkIU/ZGRMU/EYIPFSTSfU4Ev68Dt5nmV/OeAdKspArHjnzqQY8OkE8JmGGHwZihXwJsWATyeAzzS04MsQK9GsSDyAzzSA14yYpoLuV+GMQwq+DLES3YpOonlLTjOA72d1lHph/WnM44ff1GdZyFMwog3gNbMT59zxT13rsyx2w+/YxxJK8GWIlWhXdFL3ePEJa+sUjGgDeM204VunYEQbwGtGTj4n4VunYEQbQvAlafjUQgk+xEr0KxIP4DMNHfgS8CFDCD7ESgwqEg/gMw0Z+BLwQUMHPsRKTCoSD+AzDRX4UlUQZjPyCeAzDeC1s91/DtsdzWRqdJMfrocKj+p7X51k17Zv1vkk8PZpu5bd+KuhGe4PNxFf0+2FCHypKgizGVO5++1v6xMvuqOZTI1ucnTd4Y9p+M7Nvr48Kv+6ff7HtthUd/8ysOI2/FAB4Ps5OUqz9GrNgA7TzjCa+38dG91EDIgilrDrxAQ24hpRKIdNWbOlorQZ/74uEYt3a1YpR1ypRA+vm787f/DPfFAGMcRKdf/n6+ruP/ijRvRocUuxfYc18Juw5of2CYDXzP3Li1s+ykEz7Qy7MxnByOgmYkAUsYRdJ2axENeIQjlsingU/V8luvt2cygRi8XDSo64UtXnAIjG+KAafOANMcSKgJe7C7HO+pZs+w5rEBfbzdA+hQZ8qSoIsxlTYd2Id+79tDPyTh0Z3UQMiCKWsOvEBDbiGlFYD5vCuuIDzsqq6jludvX8VqK3sl29GHGlqqc/EY2JWr4CPsTKlZwXh/8pduvilmLt9RpEo+ImQ2eKAl4zW3EHH6adkc/5I6ObiAFRWj2+qg7wctiU/Xfpmx5fl1RyLWKIradyD93u8fKmYoiVbo+v9tv3b3INzX4APd6s4jhsxysu9tPOyKP8kdFNxIAoYgm7TkxgU49+xAc/E8OmsGfx4+f4ukQs5q2dyhFXquPneFZ7+/ReDLFyfYAXDxDZIN++eg2iUdrP8SV9eLN4OS1rP+LK/jBedt+vu2d1Dx7VqwpowIdYiWmFS3zAH0Zc2b9wlxNcHr+Or6rh1/GqAsBnGgrwJeDDhwR8iJUYVyQewGcaAvAl4BcIBfgQKzGvSDyAzzTLw3eHqwZ8kBCAD7ESi4rEA/hMszh8b2ICwAeJBvzNrCnnbV6d+e9jklm+x4dYiU1F4lkavj8FDeCDZHH4ECuxqkg8gM80C8OX/fUDPkiWhg+xEruKxAP4TLMs/NCskoAPEsBnGsBnmkXhB+cPBnyQAD7TAD7TLAk/PFM84IME8JlmQfiBt2v9r8S+IvEsCR9iJfYViQfwmWY5+BF3wIcJ4DMN4DPNYvBj7oAPE8BnmqXg+2fXzrASp4rEsxh8iJU4VSQewGcaI/hxrSa69/jI27UmTcxdkXiWgndvYu6KxGO2q1fKAz6WLAM/1Q7ggwTwmWYR+PEX8dpNzF+ReAxfzqnkNeHdm5i/IvEAPtMsAT/xIl63iQAViccUXiGvB+/eRICKxGP6lq0HeMWDB/BBsgS8exMhKhIP4DON8adzzvvp6UM7wAfKAvAaK6FQkXiCw6teFwA+TMzhHd998fYB39wVicf8DBzAJ5HQ8KpDO8AHSnB4ZQXgg8TiZEuXz1TLAvA0EhpefY8DPkjCwpeApxKb8+rtz5Rkh3aAp5Ee/E9fPvu0/vmr153rXOH5ewCAp5Ee/PvPqzfP2c8Pf+wXO8MXgKeSHvz3r7l9Vf34h2efvBNL+vP3WE4gVC4+8dBQQt/jRNKDf1vDs4sf/9S5rrmTLL/4Jt68QY+nkWP4N88++e8avqr2P/fZw1t9x1neCvA0Mvoc/93z6v3zznX7e8sOvlBVKJsIWZF4ho/qP3zxrjm6b8cJvt5NAJ5G7L4fP7qvn4IvVBXKJoJWJB7LgREAH3uCwTefxwKeRmyHQjEdj7QEPK0Egy9UFcomAlckHuvBj8wGmy8BTyyh4AtVhbKJ0BWJxx7eZEKZEvDUYj/OnRF8oapQNhG8IvE4wOvPFlgCnlwcRrY0gC8ATy0u8LpTQZfttQCeRlzGstWEL9sdHvBE4gTflx+EP1oJ4GnEafRqLfjjDg94InGD78kPwR+vA/A04jZevQY8cwc8wTjCd+WHKorpCuVKFqpIPI4zVKjgy26HBzyRuE5NUk5XlL01AJ5GnOHLqQruDniScZ6MaAq+7Hd4wBOJ+yxU5WjFkDvgicQDfDlSIa4APNF4mHeuLX/TWdxvHvA04mPCwZb8TWch4KnGy0yTB/mb40UDrQOeRvxMMbqXvzla0H0pN9mGdgHgfcTX3LJHX4lsHgdDjQOeRrxNKlwK7RvxS+MOeLrxOJt0WWe6bcDTyIzTiA92eMATyZzwdm0APkjmgx9pGfA0Mhv88I4e8FQyH7xtG4APkrngxzo84IlkNnjrNgAfJDPBjzcLeBqZB350Rw94KpkJ3qENwAfJLPATHR7wRDIH/JQ74IlkFninNgAfJDPAT3Z4wBOJf/hpd8ATiXd4hTvgicQ/vGsbgA8SDXijqX2KYqY5g2bL/PcxyXju8aodPXo8lfiGd28D8EHiF149VzTgicQrfAH4aOITvtCYMhjwROIRvtCZORbwROITXlmhbsNPE4BXxx+83jySgCcSb/AF4KOKL/hCczpBwBOJJ/jmHTvAxxI/8Pt3agEfS7zAH96hB3ws8QFvMuMM4InEA7zRxCOAJxJ3eLP5JwBPJM7whtMQAJ5IXOFNR6MHPJE4whsPSg54InGD751pBfhY4gTfP8MO8LHEBX7gzErAxxJ7eLtxKwFPJNbwlsMXAp5IbOFHTqAHfCyxg7cf0wrwRGIFP/59GcDHEgv4wmVoI8ATiTm820AngCcSU/ip7l4BPp4YwjsPewB4IjGCV3T3CvDxZMaJCiwrAB8kgM80gM80gM80gM80gM80gM80gM80gM80gM80gM80gM80gM80gM80gM80gM80gM80gM80gM80RvBIOgF8pgF8pgF8pgF8pgF8pvEN/91zp5v/9OWzTxffiCziGf7NM7f7/P3n1RtnNdeNyCJ+4T/8j2Nn+/41t194I7IIsV39Ww/w2NXrxCP8m2efvHO9z330eMDrhFiP9/IcD3iNEIPHUX2o4HV8pgF8pgF8pgF8pgF8pgF8pgF8pgF8pgF8pgF8pgF8pgF8pgF8pvl/4WDv/4GKksYAAAAASUVORK5CYII=" /></p>
<pre><code>#&gt; 
#&gt; [[3]]</code></pre>
<p><img role="img" src="data:image/png;base64,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" /></p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
